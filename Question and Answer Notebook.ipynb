{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f2db0320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tiktoken\n",
    "\n",
    "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "openai.api_key_path = \".env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "82092d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(filename: str) -> dict[tuple[str, str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    Read the document embeddings and their keys from a CSV.\n",
    "    \n",
    "    fname is the path to a CSV with exactly these named columns: \n",
    "        \"title\", \"heading\", \"0\", \"1\", ... up to the length of the embedding vectors.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(filename)\n",
    "    max_dim = 1535\n",
    "    return {\n",
    "           (r.title, r.mistress, r.synopsis): [r[str(i)] for i in range(max_dim + 1)] for index, r in df.iterrows()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "14161c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_embeddings = load_embeddings(\"k9_story_vectors_500.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "945b1b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str, model: str=EMBEDDING_MODEL) -> list[float]:\n",
    "    result = openai.Embedding.create(\n",
    "      model=model,\n",
    "      input=text\n",
    "    )\n",
    "    return result[\"data\"][0][\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "080eca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_similarity(x: list[float], y: list[float]) -> float:\n",
    "    \"\"\"\n",
    "    Returns the similarity between two vectors.\n",
    "    \n",
    "    Because OpenAI Embeddings are normalized to length 1, the cosine similarity is the same as the dot product.\n",
    "    \"\"\"\n",
    "    return np.dot(np.array(x), np.array(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "53fdf715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_document_sections_by_query_similarity(query: str, contexts: dict[(str, str, str), np.array]) -> list[(float, (str, str))]:\n",
    "    \"\"\"\n",
    "    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n",
    "    to find the most relevant sections. \n",
    "    \n",
    "    Return the list of document sections, sorted by relevance in descending order.\n",
    "    \"\"\"\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    document_similarities = sorted([\n",
    "        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()\n",
    "    ], reverse=True)\n",
    "    \n",
    "    return document_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0fbe9ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8296421904618271,\n",
       "  ('The Leisure Hive',\n",
       "   'Romana',\n",
       "   'The Doctor Master and Mistress decided to take a holiday to Brighton. The sea air is nice and the sights are interesting. My excitement was quickly washed away when I began to chase a ball and lost my traction. Before I knew it, I was submerged in cold seawater and I began to spark and explode. The Doctor Master and Mistress were horrified and tried their best to contain the damage. To cheer themselves up they continued their holiday on Argolis at the Leisure Hive.')),\n",
       " (0.778293563658361,\n",
       "  ('The Stones of Blood',\n",
       "   'Romana',\n",
       "   'As we arrived in modern-day Cornwall, Doctor Master and mistress began their search for the third segment of the Key to Time. Doctor Master and mistress soon encountered Professor Emilia Rumford and her friend Vivien Fay, studying the \"Nine Travellers\" standing stones in Boscombe Moor. ')),\n",
       " (0.7729829344988937,\n",
       "  ('Full Circle',\n",
       "   'Romana',\n",
       "   'I located the TARDIS in a cave, where the Marshmen were trying to gain entry. Mistress Romana decided to venture outside and I attempted to rescue her. Unfortunately, during the rescue I had my head removed from my body and I cannot remember anything else.')),\n",
       " (0.7703415656394285,\n",
       "  (\"Warrior's Gate\",\n",
       "   'Romana',\n",
       "   'Unfortunately, the winds of time shredded my memory wafers, leaving me functional but without long-term memories. The Doctor Master decided to explore our new environment and encountered robots, called Gundans. Meanwhile, Mistress Romana left to speak to the crew on the slave vessel, but she was tricked into returning to their ship.')),\n",
       " (0.7697484167969131,\n",
       "  ('School Reunion',\n",
       "   'Sarah Jane',\n",
       "   \"My sensors had detected a strange phenomenon. The chip oil in the school lunches has caused a strange increase in the performance of the students at Deffry Value School. Mistress Sarah Jane and I investigate the school and I identify the oil as Krillitane oil. I remained in the boot of mistress Sarah Jane's car while they investigated further. \"))]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_document_sections_by_query_similarity(\"What happened when you visited the beach?\", document_embeddings)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5c627478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Context separator contains 1 tokens'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SECTION_LEN = 500\n",
    "SEPARATOR = \"\\n\"\n",
    "ENCODING = \"gpt2\"  # encoding for text-davinci-003\n",
    "\n",
    "encoding = tiktoken.get_encoding(ENCODING)\n",
    "separator_len = len(encoding.encode(SEPARATOR))\n",
    "\n",
    "f\"Context separator contains {separator_len} tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "2c607f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(question: str, context_embeddings: dict) -> str:\n",
    "    text = \"\"\n",
    "    most_relevant_document_sections = order_document_sections_by_query_similarity(question, context_embeddings)\n",
    "    for section in most_relevant_document_sections:\n",
    "        score, content = section\n",
    "        story, mistress, synopsis = content\n",
    "        length = len(text)\n",
    "        syn_length = len(synopsis)\n",
    "        if (length + syn_length + separator_len) > MAX_SECTION_LEN:\n",
    "            print(syn_length)\n",
    "            break\n",
    "        text = (SEPARATOR + text + synopsis).replace(\"\\n\",\" \")\n",
    "    header = \"\"\"Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"Insufficient data.\" Always use the word \"affirmative\" instead of \"yes\" and \"negative\" instead of \"no\".\\n\\nContext:\\n\"\"\"\n",
    "    return header + \"\" + text + \"\\n\\n Q: \" + question + \"\\n A:\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "0092ffef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n"
     ]
    }
   ],
   "source": [
    "prompt = build_prompt(\n",
    "    \"Have you ever been to a marsh?\",\n",
    "    document_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "27c71955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"Insufficient data.\" Always use the word \"affirmative\" instead of \"yes\" and \"negative\" instead of \"no\".\\n\\nContext:\\n As we attempted to travel to Gallifrey, the TARDIS travelled through a Charged Vacuum Emboitement and landed on the tropical planet of Alzarius in E-Space. Once there I followed the Doctor Master to a swamp, where we encountered the aggressive Marshmen. While the Doctor and Mistress Romana attempted to maneuver the situation, I followed the Marshmen and kept watch. As I continued to trail the Marshmen, I eventually reached a river bed that I was unable to cross so I returned to the TARDIS.\\n\\n Q: Have you ever been to a marsh?\\n A:'"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "6c8affd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query(query):\n",
    "    prompt = build_prompt(query,document_embeddings)\n",
    "    response = openai.Completion.create(\n",
    "            engine=COMPLETIONS_MODEL,\n",
    "            prompt=prompt,\n",
    "            temperature=0.0,\n",
    "            max_tokens=300,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0\n",
    "        )\n",
    "    return response[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "ef5ea19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n"
     ]
    }
   ],
   "source": [
    "answer = answer_query(\"Have you ever been to a marsh?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "1a82747a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Affirmative.'"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159779c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
